{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobiML Sampling Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample trajectories in a region of interest. Based on: https://github.com/microsoft/torchgeo and https://james-brennan.github.io/posts/fast_gridding_geopandas/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import folium\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from mobiml.datasets import AISDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading AISDK data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset can be downloaded from: http://web.ais.dk/aisdata/aisdk-2018-02.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = AISDK(r\"../examples/data/aisdk_20180208_sample.zip\")\n",
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trajectory start locations for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajs = data.to_trajs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = trajs.get_start_locations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin, ymin, xmax, ymax = start.total_bounds\n",
    "print(xmin, ymin, xmax, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buffer bounding box by 0.01&deg;, which is about 1 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = xmin - 0.01\n",
    "ymin = ymin - 0.01\n",
    "xmax = xmax + 0.01\n",
    "ymax = ymax + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Buffered bounding box:\", xmin, ymin, xmax, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number of grid cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = 2  # you can specify different values for width and height\n",
    "\n",
    "\n",
    "def stride(value):\n",
    "    if isinstance(value, tuple):\n",
    "        cell_size_x = (xmax - xmin) / value[0]\n",
    "        cell_size_y = (ymax - ymin) / value[1]\n",
    "    elif isinstance(value, int):\n",
    "        cell_size_x = (xmax - xmin) / value\n",
    "        cell_size_y = (ymax - ymin) / value\n",
    "    else:\n",
    "        print(\"Please provide a tuple or int.\")\n",
    "    return cell_size_x, cell_size_y\n",
    "\n",
    "\n",
    "cell_size_x, cell_size_y = stride(n_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cells = []\n",
    "for x0 in np.arange(xmin, xmax, cell_size_x):\n",
    "    for y0 in np.arange(ymin, ymax, cell_size_y):\n",
    "        x1 = x0 + cell_size_x\n",
    "        y1 = y0 + cell_size_y\n",
    "        grid_cells.append(shapely.geometry.box(x0, y0, x1, y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = gpd.GeoDataFrame(grid_cells, columns=[\"geometry\"], crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell[\"cell\"] = cell.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cell.explore(name=\"cells\")\n",
    "\n",
    "start.explore(\n",
    "    m=m,\n",
    "    column=\"traj_id\",\n",
    "    popup=True,\n",
    "    legend=False,\n",
    "    name=\"trajectory start points\",\n",
    ")\n",
    "\n",
    "folium.TileLayer(\"CartoDB positron\").add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = gpd.sjoin(start, cell, how=\"left\", predicate=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(columns=\"index_right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine empty cells that will not be used for sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_cells = merged.cell.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells = merged.merge(cell, how=\"outer\").cell.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = [cell for cell in all_cells if cell not in filled_cells]\n",
    "\n",
    "if not diff:\n",
    "    print(\"All cells can be used for sampling.\")\n",
    "else:\n",
    "    print(\"The following cells are empty and will not be used for sampling:\", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of cells used for sampling:\", len(filled_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Points per cell:\\n\", merged.cell.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how many samples you would like in total, either as a percentage in decimals or as an absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_sample(n_sample=None, percent_sample=None, **kwargs):\n",
    "    if percent_sample:\n",
    "        n_sample = percent_sample * len(merged)\n",
    "\n",
    "    if n_sample > len(start):\n",
    "        try:\n",
    "            raise ValueError(\"Sample too big.\")\n",
    "        except ValueError:\n",
    "            print(\n",
    "                \"Your sample of\",\n",
    "                n_sample,\n",
    "                \"cannot be greater than the dataset:\",\n",
    "                len(start),\n",
    "            )\n",
    "            raise\n",
    "\n",
    "    sample_size = n_sample / len(filled_cells)\n",
    "    n_sample = math.ceil(sample_size)\n",
    "    print(\"Number of samples per cell:\", n_sample)\n",
    "\n",
    "    if n_sample > merged.cell.value_counts().min():\n",
    "        num = merged[\"cell\"].value_counts()\n",
    "        count = 0\n",
    "        for n in num:\n",
    "            if n < n_sample:\n",
    "                count += 1\n",
    "            else:\n",
    "                pass\n",
    "        print(\n",
    "            \"Not enough points in\",\n",
    "            count,\n",
    "            \"cell(s), so all points in the cell(s) will be used for sampling.\",\n",
    "        )\n",
    "\n",
    "    df_sample = merged.groupby([\"cell\"], as_index=False, group_keys=False).apply(\n",
    "        lambda x: x.sample(min(n_sample, len(x))), include_groups=False\n",
    "    )\n",
    "    df_sample[\"split\"] = 2\n",
    "    df_sample = df_sample[[\"traj_id\", \"split\"]]\n",
    "    combined = merged.merge(df_sample, how=\"left\")\n",
    "    combined.loc[combined[\"split\"] != 2, \"split\"] = 1\n",
    "    return combined\n",
    "\n",
    "\n",
    "combined = get_cell_sample(n_sample=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_sample():\n",
    "    df_sample = combined.loc[combined[\"split\"] == 2]\n",
    "    df_sample = df_sample.drop(columns=\"split\")\n",
    "    print(\"Your sample contains\", len(df_sample), \"records.\")\n",
    "    return df_sample\n",
    "\n",
    "\n",
    "df_sample = keep_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cell.explore(name=\"cells\")\n",
    "\n",
    "start.explore(\n",
    "    m=m,\n",
    "    color=\"blue\",\n",
    "    popup=True,\n",
    "    legend=False,\n",
    "    name=\"all data\",\n",
    ")\n",
    "\n",
    "df_sample.explore(\n",
    "    m=m,\n",
    "    color=\"red\",\n",
    "    popup=True,\n",
    "    legend=False,\n",
    "    name=\"sample data\",\n",
    ")\n",
    "\n",
    "folium.TileLayer(\"CartoDB positron\").add_to(m)\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset sampling with RandomTrajSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobiml.samplers import RandomTrajSampler\n",
    "\n",
    "data = AISDK(r\"../examples/data/aisdk_20180208_sample.zip\")\n",
    "data.to_trajs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = RandomTrajSampler(data).split(n_cells=(2, 2), n_sample=100)\n",
    "random_sample.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = RandomTrajSampler(data).sample(n_cells=(2, 1), percent_sample=0.4)\n",
    "sample_data.to_trajs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting at timestamps with TemporalSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset temporally at timestamp into train/dev and into train/dev/test if two timestamps are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisdk = AISDK(r\"../examples/data/aisdk_20180208_sample.zip\")\n",
    "aisdk.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobiml.samplers import TemporalSplitter\n",
    "\n",
    "aisdk = TemporalSplitter(aisdk).split_at_timestamp(\n",
    "    timestamp=datetime(2018, 2, 8, 8, 0, 0)\n",
    ")\n",
    "aisdk.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisdk = TemporalSplitter(aisdk).split_at_timestamp(\n",
    "    timestamp=datetime(2018, 2, 8, 8, 0, 0), timestamp_2=datetime(2018, 2, 8, 16, 0, 0)\n",
    ")\n",
    "aisdk.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
