{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobiML FL demo\n",
    "\n",
    "Using Flower and MobiML\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pymeos\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics, Context\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from mobiml.datasets import AISDK, MOVER_ID, SHIPTYPE\n",
    "from mobiml.transforms import TrajectoryCreator, TrajectoryAggregator\n",
    "from mobiml.preprocessing import StationaryClientExtractor, MobileClientExtractor\n",
    "from mobiml.models.trajclassifier.ais_trajectory_classifier import SummarizedAISTrajectoryClassifier, AISLoader, get_evaluate_fn, fit_round, weighted_average\n",
    "from mobiml.utils import convert_wgs_to_utm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set FL simulation output verbosity settings\n",
    "\n",
    "\n",
    "RAY_BACKEND_LOG_LEVEL: to declutter log output in shells, a low-volume log level has been chosen from [the source code](https://github.com/ray-project/ray/blob/master/src/ray/util/logging.cc#L273)\n",
    "\n",
    "RAY_DEDUP_LOGS: to see logs from all clients instead of just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['RAY_DEDUP_LOGS'] = '0'\n",
    "os.environ['RAY_BACKEND_LOG_LEVEL'] = 'fatal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/aisdk-2018-02.zip\" # download AISDK input file (1 month of data, 14G) from here http://web.ais.dk/aisdata/aisdk-2018-02.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract stationary client (antenna) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antennas = ['Point (11.96524 57.70730)', 'Point (11.63979 57.71941)', 'Point (11.78460 57.57255)']\n",
    "antenna_radius_meters = 25000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_code = convert_wgs_to_utm(11.96524, 57.70730)\n",
    "\n",
    "ids =  [{'client': i} for i in range(len(antennas))]\n",
    "df = pd.DataFrame(ids)\n",
    "df['geometry'] = gpd.GeoSeries.from_wkt(antennas)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=df.geometry, crs=4326)\n",
    "gdf = gdf.to_crs(epsg_code)\n",
    "gdf['geometry'] = gdf.buffer(antenna_radius_meters)\n",
    "\n",
    "buffered_antennas =  gdf.to_crs(4326)\n",
    "min_lon, min_lat, max_lon, max_lat = buffered_antennas.geometry.total_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"temp\"\n",
    "os.path.dirname(out_dir)\n",
    "if not os.path.exists(out_dir):\n",
    "    print(f\"{datetime.now()} Creating output directory {out_dir} ...\")\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Loading data from {path}\")\n",
    "aisdk = AISDK(path, min_lon, min_lat, max_lon, max_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Extracting client data ...\")\n",
    "antenna_gdf = StationaryClientExtractor(aisdk).extract(buffered_antennas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_feather_path = f\"{out_dir}/ais-antenna.feather\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Writing output to {stationary_feather_path}\")\n",
    "antenna_gdf.to_feather(stationary_feather_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract mobile client (vessel) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_type = 'Towing' \n",
    "antenna_radius_meters = 25000  \n",
    "bbox = [57.273, 11.196, 57.998, 12.223]  \n",
    "min_lat, min_lon, max_lat, max_lon = bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_feather_path = f\"{out_dir}/ais-vessels.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Loading data from {path}\")\n",
    "aisdk = AISDK(path, min_lon, min_lat, max_lon, max_lat)\n",
    "vessels = deepcopy(aisdk)   # AISDK(path, min_lon, min_lat, max_lon, max_lat, vessel_type)\n",
    "vessels.df = vessels.df[vessels.df.ship_type == ship_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Extracting client data ...\")\n",
    "vessel_gdf = MobileClientExtractor(aisdk).extract(vessels, antenna_radius_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{datetime.now()} Writing output to {mobile_feather_path}\")\n",
    "vessel_gdf.to_feather(mobile_feather_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare stationary and mobile client training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_resolution = 8\n",
    "\n",
    "stationary_training_file = f\"temp/training-data-stationary.pickle\"\n",
    "mobile_training_file = f\"temp/training-data-mobile.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(client_feather, outfile):\n",
    "    print(f\"{datetime.now()} Loading data from {client_feather} ...\")\n",
    "    gdf = gpd.read_feather(client_feather)\n",
    "    vessels = gdf.groupby(MOVER_ID)[[\"ship_type\", \"Name\"]].agg(pd.Series.mode)\n",
    "\n",
    "    print(f\"{datetime.now()} Extracting trips ...\")\n",
    "    trajs = TrajectoryCreator(gdf).get_trajs( gap_duration=timedelta(minutes=60))  \n",
    "\n",
    "    print(f\"{datetime.now()} Computing trajectory features ...\")\n",
    "    t_df = TrajectoryAggregator(trajs, vessels).aggregate_trajs(h3_resolution)\n",
    "\n",
    "    with open(outfile.replace(\"training-data\", \"vessel\"), \"wb\") as out_file:\n",
    "        pickle.dump(vessels, out_file)\n",
    "\n",
    "    with open(outfile, \"wb\") as out_file:\n",
    "        pickle.dump(t_df, out_file)\n",
    "    print(f\"{datetime.now()} training data written to {outfile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data(stationary_feather_path, stationary_training_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data(mobile_feather_path, mobile_training_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "vessel_types = ['Cargo', 'Passenger', 'Tanker'] \n",
    "n_features = 7\n",
    "traj_features = ['speed_max', 'speed_median', 'x_start', 'y_start', 'x_end', 'y_end', 'length'] \n",
    "test_size = 0.33\n",
    "\n",
    "trajectory_classifier_model = SummarizedAISTrajectoryClassifier(vessel_types, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from mobiml.utils import XYList\n",
    "\n",
    "\n",
    "def display_confusion_matrix(y_test, predictions, labels):\n",
    "    cm = confusion_matrix(y_test, predictions, labels=labels)\n",
    "    cm_df = DataFrame(cm, index=labels, columns=labels)\n",
    "    print(cm_df)\n",
    "\n",
    "\n",
    "def save_metrics(predictions, y_test, scenario_name):\n",
    "    if not os.path.exists(\"output\"):\n",
    "        os.makedirs(\"output\")\n",
    "\n",
    "    metrics = {\"accuracy\": accuracy_score(y_test, predictions)}\n",
    "\n",
    "    out_path = f\"output/fl-global-metrics-{scenario_name}.json\"\n",
    "    print(f\"Saving metrics to {out_path}\")\n",
    "    with open(out_path, \"w\") as fd:\n",
    "        json.dump(metrics, fd)\n",
    "\n",
    "\n",
    "def partition(X: np.ndarray, y: np.ndarray, num_partitions: int) -> XYList:\n",
    "    \"\"\"Split X and y into a number of partitions.\"\"\"\n",
    "    zipped = zip(np.array_split(X, num_partitions), np.array_split(y, num_partitions))\n",
    "    return list(zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FL client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISClient(fl.client.NumPyClient):\n",
    "    \"\"\"Client for FL model\"\"\"\n",
    "\n",
    "    def __init__(self, cid, model, partitions, data_loader) -> None:\n",
    "        super().__init__()\n",
    "        self.cid = int(cid)\n",
    "        self.model = model\n",
    "        \n",
    "        (X_train, y_train), (self.X_test, self.y_test) = data_loader.load(client_id=self.cid)\n",
    "        # Split train set into partitions and randomly use one for training.\n",
    "        partition_id = np.random.choice(partitions)\n",
    "        (self.X_train, self.y_train) = partition(X_train, y_train, partitions)[partition_id]\n",
    "        print(f\"CLIENT {self.cid} started up, will use partition {partition_id} of {partitions} partitions for training\")\n",
    "\n",
    "    def get_parameters(self, config):  # type: ignore\n",
    "        return self.model.get_model_parameters()\n",
    "\n",
    "    def fit(self, parameters, config):  # type: ignore\n",
    "        self.model.set_model_params(parameters)\n",
    "        # Ignore convergence failure due to low local epochs       \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            self.model.fit(self.X_train, self.y_train)\n",
    "            accuracy = self.model.score(self.X_train, self.y_train)\n",
    "\n",
    "        print(f\"CLIENT {self.cid} Training finished for round {config['server_round']}\")\n",
    "        return self.model.get_model_parameters(), len(self.X_train), {\"accuracy\": accuracy}\n",
    "\n",
    "    def evaluate(self, parameters, config):  # type: ignore\n",
    "        self.model.set_model_params(parameters)\n",
    "        vessel_types = self.model.classes\n",
    "        loss = log_loss(self.y_test, self.model.predict_proba(self.X_test), labels=vessel_types)\n",
    "        accuracy = self.model.score(self.X_test, self.y_test)\n",
    "        print(f\"CLIENT {self.cid} accuracy {accuracy}\")\n",
    "        return loss, len(self.X_test), {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_client_fn(model, lookup, data_partitions, dloader):\n",
    "    \"\"\" Is called in every training round to initialise a new Client object. \"\"\"\n",
    "\n",
    "    def client_fn(cid: str):     \n",
    "        print(f\"******* {int(lookup[cid])} **********\")\n",
    "        return AISClient(int(lookup[cid]), trajectory_classifier_model, data_partitions, dloader).to_client()\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start FL \n",
    "\n",
    "https://flower.ai/docs/framework/how-to-implement-strategies.html\n",
    "\n",
    "https://flower.ai/docs/framework/ref-api/flwr.simulation.start_simulation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FL with static data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data_loader = AISLoader(vessel_types, traj_features, test_size, path=stationary_training_file)\n",
    "static_scenario_name = Path(stationary_training_file).stem.replace(\"training-data-\", \"\")\n",
    "\n",
    "\n",
    "static_strategy = fl.server.strategy.FedAvg(\n",
    "        min_available_clients=2,\n",
    "        evaluate_fn=get_evaluate_fn(trajectory_classifier_model, static_data_loader, static_scenario_name),\n",
    "        on_fit_config_fn=fit_round,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_per_round = 3\n",
    "rounds = 10\n",
    "client_data_partitions = 2\n",
    "\n",
    "client_mapping = {  # flwr client id -> MMSI\n",
    "     '0': 0,\n",
    "     '1': 1,\n",
    "     '2': 2,\n",
    "}\n",
    "\n",
    "\n",
    "client_fn = generate_client_fn(trajectory_classifier_model, client_mapping, client_data_partitions, static_data_loader)\n",
    "\n",
    "print(f\"{datetime.now()} Starting training\")\n",
    "\n",
    "fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=clients_per_round,\n",
    "        config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "        strategy=static_strategy\n",
    ")\n",
    "print(f\"{datetime.now()} Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FL with mobile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_data_loader = AISLoader(vessel_types, traj_features, test_size, path=mobile_training_file)\n",
    "mobile_scenario_name = Path(mobile_training_file).stem.replace(\"training-data-\", \"\")\n",
    "\n",
    "\n",
    "mobile_strategy = fl.server.strategy.FedAvg(\n",
    "        min_available_clients=2,\n",
    "        evaluate_fn=get_evaluate_fn(trajectory_classifier_model, mobile_data_loader, mobile_scenario_name),\n",
    "        on_fit_config_fn=fit_round,\n",
    "        evaluate_metrics_aggregation_fn=weighted_average,\n",
    "        fit_metrics_aggregation_fn=weighted_average,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_per_round = 4\n",
    "rounds = 10\n",
    "client_data_partitions = 3\n",
    "\n",
    "\n",
    "client_mapping = {  # flwr client id -> MMSI\n",
    "     '0': 236111925,\n",
    "     '1': 219012959,\n",
    "     '2': 235662000,\n",
    "     '3': 265737220,\n",
    "}\n",
    "\n",
    "\n",
    "client_fn = generate_client_fn(trajectory_classifier_model, client_mapping, client_data_partitions, mobile_data_loader)\n",
    "\n",
    "print(f\"{datetime.now()} Starting training\")\n",
    "fl.simulation.start_simulation(\n",
    "        client_fn=client_fn,\n",
    "        num_clients=clients_per_round,\n",
    "        config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "        strategy=mobile_strategy\n",
    ")\n",
    "print(f\"{datetime.now()} Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
